{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "from pyro.distributions.testing.fakes import NonreparameterizedBeta\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "assert pyro.__version__.startswith('1.9.1')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "from vectorized_loop.ops import Index\n",
    "import vectorized_loop as vec\n",
    "\n",
    "import warnings\n",
    "pyro.primitives.enable_validation(False)\n",
    "warnings.filterwarnings('ignore')\n",
    "pyro.set_rng_seed(20)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "max_steps = 10000\n",
    "\n",
    "def param_abs_error(name, target):\n",
    "    return torch.sum(torch.abs(target - pyro.param(name))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb61a2eea514c95bdd86822fa8ba91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Did 156 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7986 & 0.7642\n",
      "Doing inference with use_decaying_avg_baseline=False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed13c674c1824665801ba59355e52b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Did 253 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7990 & 0.7468\n"
     ]
    }
   ],
   "source": [
    "class BernoulliBetaExample:\n",
    "\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha0 = 10.0\n",
    "        self.beta0 = 10.0\n",
    "        self.data = torch.zeros(10)\n",
    "        self.data[0:6] = torch.ones(6)\n",
    "        self.n_data = self.data.size(0)\n",
    "        self.alpha_n = self.data.sum() + self.alpha0\n",
    "        self.beta_n = - self.data.sum() + torch.tensor(self.beta0 + self.n_data)\n",
    "        self.alpha_q_0 = 15.0\n",
    "        self.beta_q_0 = 15.0\n",
    "\n",
    "    def model(self, use_decaying_avg_baseline):\n",
    "        f = pyro.sample(\"latent_fairness\", dist.Beta(self.alpha0, self.beta0))\n",
    "        with pyro.plate(\"data_plate\"):\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(f), obs=self.data)\n",
    "\n",
    "    def guide(self, use_decaying_avg_baseline):\n",
    "        alpha_q = pyro.param(\"alpha_q\", torch.tensor(self.alpha_q_0),\n",
    "                             constraint=constraints.positive)\n",
    "        beta_q = pyro.param(\"beta_q\", torch.tensor(self.beta_q_0),\n",
    "                            constraint=constraints.positive)\n",
    "        baseline_dict = {'use_decaying_avg_baseline': use_decaying_avg_baseline,\n",
    "                         'baseline_beta': 0.90}\n",
    "        pyro.sample(\"latent_fairness\", NonreparameterizedBeta(alpha_q, beta_q),\n",
    "                    infer=dict(baseline=baseline_dict))\n",
    "\n",
    "    def do_inference(self, use_decaying_avg_baseline, tolerance=0.80):\n",
    "        pyro.clear_param_store()\n",
    "\n",
    "        optimizer = optim.Adam({\"lr\": .0005, \"betas\": (0.93, 0.999)})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=TraceGraph_ELBO())\n",
    "        print(\"Doing inference with use_decaying_avg_baseline=%s\" % use_decaying_avg_baseline)\n",
    "\n",
    "        for k in (epoch := tqdm(range(self.max_steps))):\n",
    "            loss = svi.step(use_decaying_avg_baseline)\n",
    "            epoch.set_description(f\"Loss: {loss:.2f}\")\n",
    "\n",
    "            alpha_error = param_abs_error(\"alpha_q\", self.alpha_n)\n",
    "            beta_error = param_abs_error(\"beta_q\", self.beta_n)\n",
    "\n",
    "            if alpha_error < tolerance and beta_error < tolerance:\n",
    "                break\n",
    "\n",
    "        print(\"\\nDid %d steps of inference.\" % k)\n",
    "        print((\"Final absolute errors for the two variational parameters \" +\n",
    "               \"were %.4f & %.4f\") % (alpha_error, beta_error))\n",
    "\n",
    "bbe = BernoulliBetaExample(max_steps=max_steps)\n",
    "bbe.do_inference(use_decaying_avg_baseline=True)\n",
    "bbe.do_inference(use_decaying_avg_baseline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512204a540f0473ba691b7e1cbb17c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Did 253 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7436 & 0.7996\n",
      "Doing inference with use_decaying_avg_baseline=False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95691db754a2442da32fe3eed6b9afa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Did 430 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7993 & 0.7812\n"
     ]
    }
   ],
   "source": [
    "class BernoulliBetaExample:\n",
    "    \n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha0 = 10.0\n",
    "        self.beta0 = 10.0\n",
    "        self.data = torch.zeros(10)\n",
    "        self.data[0:6] = torch.ones(6)\n",
    "        self.n_data = self.data.size(0)\n",
    "        self.alpha_n = self.data.sum() + self.alpha0\n",
    "        self.beta_n = - self.data.sum() + torch.tensor(self.beta0 + self.n_data)\n",
    "        self.alpha_q_0 = 15.0\n",
    "        self.beta_q_0 = 15.0\n",
    "\n",
    "    @vec.vectorize\n",
    "    def model(s: vec.State, self, use_decaying_avg_baseline):\n",
    "        s.f = pyro.sample(\"latent_fairness\", dist.Beta(self.alpha0, self.beta0))\n",
    "        for s.i in vec.range(\"data_plate\", self.n_data, vectorized=True, device=device):\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(s.f), obs=Index(self.data)[s.i])\n",
    "                    \n",
    "    def guide(self, use_decaying_avg_baseline):\n",
    "        alpha_q = pyro.param(\"alpha_q\", torch.tensor(self.alpha_q_0),\n",
    "                             constraint=constraints.positive)\n",
    "        beta_q = pyro.param(\"beta_q\", torch.tensor(self.beta_q_0),\n",
    "                            constraint=constraints.positive)\n",
    "        baseline_dict = {'use_decaying_avg_baseline': use_decaying_avg_baseline,\n",
    "                         'baseline_beta': 0.90}\n",
    "        pyro.sample(\"latent_fairness\", NonreparameterizedBeta(alpha_q, beta_q),\n",
    "                    infer=dict(baseline=baseline_dict))\n",
    "\n",
    "    def do_inference(self, use_decaying_avg_baseline, tolerance=0.80):\n",
    "        pyro.clear_param_store()\n",
    "        vec.clear_allocators()\n",
    "\n",
    "        optimizer = optim.Adam({\"lr\": .0005, \"betas\": (0.93, 0.999)})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=vec.TraceGraph_ELBO())\n",
    "        print(\"Doing inference with use_decaying_avg_baseline=%s\" % use_decaying_avg_baseline)\n",
    "\n",
    "        for k in (epoch := tqdm(range(self.max_steps))):\n",
    "            loss = svi.step(use_decaying_avg_baseline)\n",
    "            epoch.set_description(f\"Loss: {loss:.2f}\")\n",
    "\n",
    "            alpha_error = param_abs_error(\"alpha_q\", self.alpha_n)\n",
    "            beta_error = param_abs_error(\"beta_q\", self.beta_n)\n",
    "\n",
    "            if alpha_error < tolerance and beta_error < tolerance:\n",
    "                break\n",
    "\n",
    "        print(\"\\nDid %d steps of inference.\" % k)\n",
    "        print((\"Final absolute errors for the two variational parameters \" +\n",
    "               \"were %.4f & %.4f\") % (alpha_error, beta_error))\n",
    "\n",
    "bbe = BernoulliBetaExample(max_steps=max_steps)\n",
    "bbe.do_inference(use_decaying_avg_baseline=True)\n",
    "bbe.do_inference(use_decaying_avg_baseline=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
